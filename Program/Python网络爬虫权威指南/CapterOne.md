# Chapter One：初见网络爬虫

## 什么是网页爬取

网页抓取是一种通过多种手段收集网络数据的方式，不光是通过与 API 交互（或者直接与浏览器交互）的方式。最常用的方法是写一个自动化程序向网络服务器请求数据(通常是用 HTML 表单或其他网页文件），然后对数据进行解析，提取需要的信息。

## 1.1 网络连接
我们通过一个例子让你对浏览器获取信息的过程又一个基本的认识。

- 场景
Alice 有一台网络服务器，Bob有一台台式机正试图连接到 Alice 的服务器。当一台机器想与另一台机器对话时，下面某个行为将会发生

- Bob 的电脑发送一串 1 和 0 比特值，表示电路上的高低电压